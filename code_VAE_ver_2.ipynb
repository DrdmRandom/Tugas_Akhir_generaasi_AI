{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Importimg Library",
   "id": "cd3b7a58bc7a4696"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T04:03:30.903898Z",
     "start_time": "2024-12-26T04:03:26.873582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils"
   ],
   "id": "edc620e2e5bfb1c4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Hyperparameters & Device",
   "id": "a92ac706b1e935d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T04:04:35.958404Z",
     "start_time": "2024-12-26T04:04:35.945899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "lr_initial = 1e-3\n",
    "num_epochs = 2       # silakan ganti sesuai kebutuhan\n",
    "image_size = 64\n",
    "save_sample_every = 5 # save recon & sample images tiap beberapa epoch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device :\", device)\n",
    "print(\"Device       :\",torch.cuda.get_device_name(0))\n",
    "print(\"Cude Version :\", torch.version.cuda)"
   ],
   "id": "86e6d460707597fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device : cuda\n",
      "Device       : NVIDIA GeForce GTX 1060 6GB\n",
      "Cude Version : 11.8\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Dataset & DataLoader",
   "id": "2bb05e3c9fc61f38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_dir = r\"C:\\Users\\dawwi\\Downloads\\Dataset\"  # Pastikan punya subfolder di dalamnya\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ],
   "id": "9c04964ed8974f9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Definisi Encoder & Decoder",
   "id": "7ce805b8b327ded6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1),  # (B, 32, 32, 32)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), # (B, 64, 16, 16)\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64 * 16 * 16, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64 * 16 * 16, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 64 * 16 * 16)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),  # (B, 32, 32, 32)\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1),   # (B, 3, 64, 64)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z).view(-1, 64, 16, 16)\n",
    "        x = self.deconv(x)\n",
    "        return x\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ],
   "id": "9b2b2b1ca914b50c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Inisialisasi Model, Optimizer, Scheduler",
   "id": "73d9f851431c0892"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "encoder = Encoder(latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim).to(device)\n",
    "\n",
    "params = list(encoder.parameters()) + list(decoder.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=lr_initial)\n",
    "\n",
    "# Contoh StepLR: setiap 5 epoch, LR turun dikali 0.5\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ],
   "id": "4038ca2b91be4768"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Loss Function (menggunakan reduction='mean')",
   "id": "b95d2c81a99daedb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    BCE + KL Divergence, dengan BCE direduksi mean per pixel.\n",
    "    \"\"\"\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='mean')\n",
    "    # KLD = 0.5 * sum( var + mu^2 - logvar - 1 )\n",
    "    # tapi kita pakai formula VAE standard:\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ],
   "id": "bdbab3772064b349"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Fungsi Helper (Simpan Recon & Sampling)",
   "id": "58124b3df9ceb74a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_reconstructions(encoder, decoder, images, epoch, save_dir=\"samples\"):\n",
    "    \"\"\"\n",
    "    Menyimpan hasil rekonstruksi beberapa gambar (images) ke file.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        mu, logvar = encoder(images)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        recon = decoder(z)\n",
    "    # Buat grid (asli + recon) untuk perbandingan\n",
    "    # misal: baris pertama = real images, baris kedua = recon images\n",
    "    images_concat = torch.cat([images, recon], dim=0)\n",
    "    grid = vutils.make_grid(images_concat.cpu(), nrow=images.size(0), normalize=True)\n",
    "    filename = os.path.join(save_dir, f\"recon_epoch_{epoch}.png\")\n",
    "    vutils.save_image(grid, filename)\n",
    "    print(f\"Saved reconstruction: {filename}\")"
   ],
   "id": "3a800adc5bb4c52a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_sampling(decoder, epoch, num_samples=8, save_dir=\"samples\"):\n",
    "    \"\"\"\n",
    "    Sampling random z dari N(0, I), generate via decoder, simpan sebagai grid.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, latent_dim, device=device)\n",
    "        samples = decoder(z)\n",
    "    grid = vutils.make_grid(samples.cpu(), nrow=num_samples, normalize=True)\n",
    "    filename = os.path.join(save_dir, f\"sample_epoch_{epoch}.png\")\n",
    "    vutils.save_image(grid, filename)\n",
    "    print(f\"Saved sampling: {filename}\")"
   ],
   "id": "3f85461392985ced"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Variabel Logging",
   "id": "af9e803edee0edf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loss_history_iter = []    # loss di setiap iterasi\n",
    "lr_history_iter = []      # learning rate di setiap iterasi\n",
    "loss_history_epoch = []   # average loss per epoch\n",
    "\n",
    "total_iters = 0"
   ],
   "id": "71df50024f4b4e35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 8. Training Loop",
   "id": "889c19695677a49f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Start Training VAE...\")\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_loss = 0.0\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # Forward\n",
    "        mu, logvar = encoder(imgs)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        recon = decoder(z)\n",
    "\n",
    "        # Hitung loss\n",
    "        loss = loss_function(recon, imgs, mu, logvar)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        batch_loss = loss.item()\n",
    "        loss_history_iter.append(batch_loss)\n",
    "        lr_history_iter.append(optimizer.param_groups[0]['lr'])\n",
    "        epoch_loss += batch_loss\n",
    "        total_iters += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Step [{i}/{len(dataloader)}], \"\n",
    "                  f\"Loss: {batch_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # Rata-rata loss per epoch\n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    loss_history_epoch.append(avg_epoch_loss)\n",
    "\n",
    "    # Scheduler step (menurunkan LR)\n",
    "    scheduler.step()\n",
    "\n",
    "    # Simpan recon & sample setiap 'save_sample_every' epoch\n",
    "    if epoch % save_sample_every == 0:\n",
    "        # Ambil batch pertama dari data loader (buat recon)\n",
    "        example_imgs, _ = next(iter(dataloader))\n",
    "        example_imgs = example_imgs[:8].to(device)  # ambil 8 gambar\n",
    "        save_reconstructions(encoder, decoder, example_imgs, epoch)\n",
    "        save_sampling(decoder, epoch, num_samples=8)\n",
    "\n",
    "print(\"Training Finished.\")"
   ],
   "id": "fb888d0b112e9218"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 9. Simpan Model",
   "id": "f4d9236d45d1a113"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "torch.save(encoder.state_dict(), \"saved_models/vae_encoder.pth\")\n",
    "torch.save(decoder.state_dict(), \"saved_models/vae_decoder.pth\")\n",
    "print(\"Model saved to 'saved_models' folder.\")"
   ],
   "id": "2446479cb525baff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 10. Plot Loss & Learning Rate",
   "id": "72f8153c4806fc4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.title(\"VAE Loss per Iteration\")\n",
    "plt.plot(loss_history_iter, label=\"Loss (iter)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.title(\"VAE Loss per Epoch\")\n",
    "plt.plot(loss_history_epoch, label=\"Loss (epoch)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.title(\"Learning Rate over Iterations\")\n",
    "plt.plot(lr_history_iter, label=\"LR\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "c77f3bc0ab5c1a6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 11. Visualisasi Latent Space (t-SNE pada mu)",
   "id": "9f41b1fdb05d5fc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_latent_tsne(encoder, device, dataloader, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Mengumpulkan mu dari batch (total n_samples), lalu t-SNE 2D.\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    all_mu = []\n",
    "    total_collected = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            mu, logvar = encoder(images)\n",
    "            all_mu.append(mu.cpu().numpy())\n",
    "            total_collected += images.size(0)\n",
    "            if total_collected >= n_samples:\n",
    "                break\n",
    "\n",
    "    all_mu = np.concatenate(all_mu, axis=0)\n",
    "    all_mu = all_mu[:n_samples]  # trim jika kebanyakan\n",
    "\n",
    "    print(\"Running t-SNE on latent (mu), might take a while ...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=30, n_iter=1000)\n",
    "    mu_2d = tsne.fit_transform(all_mu)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(mu_2d[:,0], mu_2d[:,1], s=10, alpha=0.7, c='blue')\n",
    "    plt.title(\"Latent Space (mu) Visualization via t-SNE\")\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.show()\n",
    "\n",
    "# Jalankan t-SNE (opsional):\n",
    "visualize_latent_tsne(encoder, device, dataloader, n_samples=1000)"
   ],
   "id": "b11b96202cf9bc4a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
