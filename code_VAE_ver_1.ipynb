{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Importimg Library",
   "id": "cd3b7a58bc7a4696"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T03:57:12.409670Z",
     "start_time": "2024-12-26T03:57:08.060350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ],
   "id": "edc620e2e5bfb1c4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyperparameters",
   "id": "a92ac706b1e935d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T03:57:12.456012Z",
     "start_time": "2024-12-26T03:57:12.416352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "lr = 1e-3\n",
    "num_epochs = 2\n",
    "image_size = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Memeriksa apakah CUDA tersedia\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Version:\", torch.version.cuda)"
   ],
   "id": "86e6d460707597fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce GTX 1060 6GB\n",
      "CUDA Version: 11.8\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Definisi Encoder & Decoder (VAE)",
   "id": "2bb05e3c9fc61f38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T03:57:12.486851Z",
     "start_time": "2024-12-26T03:57:12.472348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64 * 16 * 16, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64 * 16 * 16, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)         # (batch_size, 64*16*16)\n",
    "        mu = self.fc_mu(x)       # (batch_size, latent_dim)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 64 * 16 * 16)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1),\n",
    "            nn.Sigmoid()  # output [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z).view(-1, 64, 16, 16)  # (batch_size, 64, 16, 16)\n",
    "        x = self.deconv(x)                  # (batch_size, 3, 64, 64)\n",
    "        return x\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ],
   "id": "cdb93cb0633ee2a8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset & DataLoader",
   "id": "bebfc3698fc5b62c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T03:57:13.160951Z",
     "start_time": "2024-12-26T03:57:12.503487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root=r\"dataset-path-here\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ],
   "id": "16b1f2de25e075bc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Inisialisasi Model, Optimizer, dan Loss",
   "id": "f8494aa512617373"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T03:57:13.332643Z",
     "start_time": "2024-12-26T03:57:13.177619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = Encoder(latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # recon_x = hasil rekonstruksi\n",
    "    # x       = gambar asli\n",
    "    # mu, logvar = parameter distribusi q(z|x)\n",
    "\n",
    "    # Binary Cross Entropy\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    # KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ],
   "id": "1c954f68435cad88",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Variabel untuk Logging",
   "id": "fe4600ce90a5be3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T03:57:13.364622Z",
     "start_time": "2024-12-26T03:57:13.349672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_history = []\n",
    "lr_history = []  # untuk menyimpan learning rate di setiap iterasi"
   ],
   "id": "8320640308a03892",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "91f0a2fd6e2b3e9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T04:02:08.269382Z",
     "start_time": "2024-12-26T03:57:13.382283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Start Training VAE...\")\n",
    "total_iterations = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        img = img.to(device)\n",
    "\n",
    "        # Forward Encoder\n",
    "        mu, logvar = encoder(img)\n",
    "        z = reparameterize(mu, logvar)\n",
    "\n",
    "        # Forward Decoder\n",
    "        recon = decoder(z)\n",
    "\n",
    "        # Hitung Loss\n",
    "        loss = loss_function(recon, img, mu, logvar)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Simpan loss & LR\n",
    "        loss_history.append(loss.item())\n",
    "        # Jika hanya satu param_group (umum di Adam), cukup ambil [0]\n",
    "        lr_history.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        total_iterations += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(dataloader)}], \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"VAE Training Finished.\")"
   ],
   "id": "a7f8d9e7bbcfbbaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training VAE...\n",
      "Epoch [1/2], Step [0/2290], Loss: 547730.6250\n",
      "Epoch [1/2], Step [100/2290], Loss: 441571.8438\n",
      "Epoch [1/2], Step [200/2290], Loss: 425328.0625\n",
      "Epoch [1/2], Step [300/2290], Loss: 422743.3750\n",
      "Epoch [1/2], Step [400/2290], Loss: 431723.3750\n",
      "Epoch [1/2], Step [500/2290], Loss: 428694.6875\n",
      "Epoch [1/2], Step [600/2290], Loss: 410803.8125\n",
      "Epoch [1/2], Step [700/2290], Loss: 412631.9688\n",
      "Epoch [1/2], Step [800/2290], Loss: 407981.0625\n",
      "Epoch [1/2], Step [900/2290], Loss: 418553.6875\n",
      "Epoch [1/2], Step [1000/2290], Loss: 413378.1875\n",
      "Epoch [1/2], Step [1100/2290], Loss: 418583.0000\n",
      "Epoch [1/2], Step [1200/2290], Loss: 404006.1250\n",
      "Epoch [1/2], Step [1300/2290], Loss: 418499.0625\n",
      "Epoch [1/2], Step [1400/2290], Loss: 410117.8438\n",
      "Epoch [1/2], Step [1500/2290], Loss: 423616.7188\n",
      "Epoch [1/2], Step [1600/2290], Loss: 414202.2188\n",
      "Epoch [1/2], Step [1700/2290], Loss: 422017.0625\n",
      "Epoch [1/2], Step [1800/2290], Loss: 416728.7188\n",
      "Epoch [1/2], Step [1900/2290], Loss: 403042.0625\n",
      "Epoch [1/2], Step [2000/2290], Loss: 403668.0000\n",
      "Epoch [1/2], Step [2100/2290], Loss: 412903.8750\n",
      "Epoch [1/2], Step [2200/2290], Loss: 411390.9062\n",
      "Epoch [2/2], Step [0/2290], Loss: 413343.0938\n",
      "Epoch [2/2], Step [100/2290], Loss: 412096.4688\n",
      "Epoch [2/2], Step [200/2290], Loss: 421620.3438\n",
      "Epoch [2/2], Step [300/2290], Loss: 414615.7188\n",
      "Epoch [2/2], Step [400/2290], Loss: 413325.5000\n",
      "Epoch [2/2], Step [500/2290], Loss: 404932.2188\n",
      "Epoch [2/2], Step [600/2290], Loss: 418150.7188\n",
      "Epoch [2/2], Step [700/2290], Loss: 418352.0938\n",
      "Epoch [2/2], Step [800/2290], Loss: 416999.3125\n",
      "Epoch [2/2], Step [900/2290], Loss: 403571.4062\n",
      "Epoch [2/2], Step [1000/2290], Loss: 425736.4375\n",
      "Epoch [2/2], Step [1100/2290], Loss: 395546.9688\n",
      "Epoch [2/2], Step [1200/2290], Loss: 417427.0312\n",
      "Epoch [2/2], Step [1300/2290], Loss: 417081.0312\n",
      "Epoch [2/2], Step [1400/2290], Loss: 398478.7188\n",
      "Epoch [2/2], Step [1500/2290], Loss: 418707.7188\n",
      "Epoch [2/2], Step [1600/2290], Loss: 419734.8750\n",
      "Epoch [2/2], Step [1700/2290], Loss: 419795.1250\n",
      "Epoch [2/2], Step [1800/2290], Loss: 398985.1250\n",
      "Epoch [2/2], Step [1900/2290], Loss: 412964.7500\n",
      "Epoch [2/2], Step [2000/2290], Loss: 428538.3125\n",
      "Epoch [2/2], Step [2100/2290], Loss: 410679.4688\n",
      "Epoch [2/2], Step [2200/2290], Loss: 394895.1250\n",
      "VAE Training Finished.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Menyimpan Model (Encoder & Decoder)",
   "id": "b306268d7c0108de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T04:02:08.628815Z",
     "start_time": "2024-12-26T04:02:08.583166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "encoder_save_path = \"saved_models/VEE Generation 1/vae_encoder.pth\"\n",
    "decoder_save_path = \"saved_models/VEE Generation 1/vae_decoder.pth\"\n",
    "\n",
    "torch.save(encoder.state_dict(), encoder_save_path)\n",
    "torch.save(decoder.state_dict(), decoder_save_path)\n",
    "\n",
    "print(f\"Encoder disimpan ke: {encoder_save_path}\")\n",
    "print(f\"Decoder disimpan ke: {decoder_save_path}\")"
   ],
   "id": "6b2bee00df9f6fde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder disimpan ke: saved_models/VEE Generation 1/vae_encoder.pth\n",
      "Decoder disimpan ke: saved_models/VEE Generation 1/vae_decoder.pth\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualisasi Loss & Learning Rate",
   "id": "757968778043e46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T04:02:08.691332Z",
     "start_time": "2024-12-26T04:02:08.679292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_learning_rate_and_loss(loss_history, lr_history):\n",
    "    \"\"\"\n",
    "    Visualisasi Training Loss dan Learning Rate selama iterasi.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(\"Training Loss (VAE)\")\n",
    "    plt.plot(loss_history, label=\"VAE Loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(\"Learning Rate Over Iterations\")\n",
    "    plt.plot(lr_history, label=\"Learning Rate\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"LR\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "13aa47b90713d62a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualisasi Latent Space (t-SNE)",
   "id": "bbcab6c60a9c1025"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T04:02:08.799415Z",
     "start_time": "2024-12-26T04:02:08.785919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_latent_space(encoder, device, dataloader, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Mengumpulkan mu dari batch pertama yang berisi total n_samples,\n",
    "    lalu melakukan t-SNE (2D) untuk melihat distribusi latent space.\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    all_mu = []\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            mu, logvar = encoder(images)\n",
    "\n",
    "            # Ambil mu ke CPU, simpan\n",
    "            all_mu.append(mu.cpu().numpy())\n",
    "\n",
    "            total += images.size(0)\n",
    "            if total >= n_samples:\n",
    "                break\n",
    "\n",
    "    # Gabung semua mu\n",
    "    all_mu = np.concatenate(all_mu, axis=0)\n",
    "    # Truncate jika melebihi n_samples\n",
    "    all_mu = all_mu[:n_samples]\n",
    "\n",
    "    # t-SNE\n",
    "    print(\"Running t-SNE on latent vectors (mu)...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=30, n_iter=1000)\n",
    "    mu_2d = tsne.fit_transform(all_mu)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(mu_2d[:, 0], mu_2d[:, 1], alpha=0.7, s=10, c='blue')\n",
    "    plt.title(\"Latent Space Visualization via t-SNE\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# Contoh penggunaan:\n",
    "# visualize_learning_rate_and_loss(loss_history, lr_history)\n",
    "# visualize_latent_space(encoder, device, dataloader, n_samples=1000)\n"
   ],
   "id": "e569d33dac2a2055",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
