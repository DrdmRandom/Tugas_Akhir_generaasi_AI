{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  Importing Library",
   "id": "3ede05b1f5de5c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T23:34:12.548398Z",
     "start_time": "2024-12-26T23:34:05.763995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n"
   ],
   "id": "284c0317455743cf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyperparameters",
   "id": "990e37683dcfec91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T23:34:14.182507Z",
     "start_time": "2024-12-26T23:34:14.125290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "image_size = 64\n",
    "nz = 100\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "num_epochs = 10\n",
    "r1_gamma = 10.0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Memeriksa apakah CUDA tersedia\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Jika True, berarti GPU Anda bisa digunakan oleh PyTorch\n",
    "# Nama GPU (untuk device index 0)\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.version.cuda)\n"
   ],
   "id": "4b35f68bfff6a063",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1060 6GB\n",
      "11.8\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Dataset & Augmentations",
   "id": "b91a134a62ec9a9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T23:34:17.196804Z",
     "start_time": "2024-12-26T23:34:16.835610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Ganti path di bawah sesuai lokasi dataset Anda\n",
    "data_dir = r\"C:\\Users\\dawwi\\Downloads\\Dataset 4\"\n",
    "dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ],
   "id": "5c667aeee4fafccc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Definisi Model DCGAN (Generator & Discriminator)",
   "id": "e6d570dd58736392"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T23:34:19.010972Z",
     "start_time": "2024-12-26T23:34:18.990977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf=64, nc=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ],
   "id": "b06749b0bde1c76c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T23:34:20.823859Z",
     "start_time": "2024-12-26T23:34:20.646066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=3, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()  # DCGAN standard\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "netG = Generator(nz).to(device)\n",
    "netD = Discriminator().to(device)"
   ],
   "id": "f10d5cfae3c44539",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Loss, Optimizer, Scheduler",
   "id": "75203008d9373fe5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T23:34:23.108803Z",
     "start_time": "2024-12-26T23:34:23.042560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# Scheduler: menurunkan LR setengah setiap 10 epoch\n",
    "schedulerD = StepLR(optimizerD, step_size=10, gamma=0.5)\n",
    "schedulerG = StepLR(optimizerG, step_size=10, gamma=0.5)\n",
    "\n",
    "# Logging\n",
    "lossD_history = []\n",
    "lossG_history = []\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)"
   ],
   "id": "745b1d78731c20a8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Training Loop (with R1 Regularization)",
   "id": "4ad9f13132f211f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T23:34:24.782668Z",
     "start_time": "2024-12-26T23:34:24.771264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Logging Loss *per-epoch*\n",
    "lossD_epoch = []\n",
    "lossG_epoch = []"
   ],
   "id": "401110da891ce1bb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-26T23:34:26.293045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_lossD = 0.0\n",
    "    epoch_lossG = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        b_size = imgs.size(0)\n",
    "        total_batches += 1\n",
    "\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        # --------------------------------------\n",
    "        # (A) Train Discriminator\n",
    "        # --------------------------------------\n",
    "        netD.zero_grad()\n",
    "\n",
    "        # Real path\n",
    "        real_imgs.requires_grad_(True)\n",
    "        label_real = torch.full((b_size,), 1.0, dtype=torch.float, device=device)\n",
    "        output_real = netD(real_imgs).view(-1)\n",
    "        lossD_real = criterion(output_real, label_real)\n",
    "        lossD_real.backward(retain_graph=True)\n",
    "\n",
    "        # R1 penalty\n",
    "        grad_real = torch.autograd.grad(\n",
    "            outputs=output_real.sum(),\n",
    "            inputs=real_imgs,\n",
    "            create_graph=True\n",
    "        )[0]  # shape: (b_size, 3, 64, 64)\n",
    "        r1_penalty = r1_gamma * grad_real.pow(2).view(b_size, -1).sum(1).mean()\n",
    "        r1_penalty.backward()\n",
    "\n",
    "        real_imgs.requires_grad_(False)\n",
    "\n",
    "        # Fake path\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake_imgs = netG(noise)\n",
    "        label_fake = torch.full((b_size,), 0.0, dtype=torch.float, device=device)\n",
    "        output_fake = netD(fake_imgs.detach()).view(-1)\n",
    "        lossD_fake = criterion(output_fake, label_fake)\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        lossD_total = lossD_real + lossD_fake + r1_penalty\n",
    "        optimizerD.step()\n",
    "\n",
    "        # --------------------------------------\n",
    "        # (B) Train Generator\n",
    "        # --------------------------------------\n",
    "        netG.zero_grad()\n",
    "        label_fake_forG = torch.full((b_size,), 1.0, dtype=torch.float, device=device)\n",
    "        output_fake_forG = netD(fake_imgs).view(-1)\n",
    "        lossG = criterion(output_fake_forG, label_fake_forG)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        epoch_lossD += lossD_total.item()\n",
    "        epoch_lossG += lossG.item()\n",
    "\n",
    "    # Rata-rata Loss per epoch\n",
    "    avg_lossD = epoch_lossD / total_batches\n",
    "    avg_lossG = epoch_lossG / total_batches\n",
    "    lossD_epoch.append(avg_lossD)\n",
    "    lossG_epoch.append(avg_lossG)\n",
    "\n",
    "    # Step the scheduler each epoch\n",
    "    schedulerD.step()\n",
    "    schedulerG.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | LossD: {avg_lossD:.4f} | LossG: {avg_lossG:.4f} | \"\n",
    "          f\"LR_D: {schedulerD.get_last_lr()[0]:.6f} | LR_G: {schedulerG.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    # Save sample image di setiap epoch\n",
    "    with torch.no_grad():\n",
    "        fake_sample = netG(fixed_noise).detach().cpu()\n",
    "    grid = make_grid(fake_sample, nrow=8, normalize=True)\n",
    "    os.makedirs(\"samples\", exist_ok=True)\n",
    "    save_image(grid, f\"samples/epoch_{epoch+1}.png\")\n",
    "    print(f\"Sample image saved: samples/epoch_{epoch+1}.png\")\n",
    "\n",
    "print(\"Training Finished.\")"
   ],
   "id": "740fd700174de6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Plot Loss vs. Iteration",
   "id": "ab3d3e95fa95b087"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Loss (D & G) over Iterations\")\n",
    "plt.plot(lossD_history, label=\"LossD\")\n",
    "plt.plot(lossG_history, label=\"LossG\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"training_loss_plot.png\")\n",
    "plt.show()\n",
    "print(\"Plot saved: training_loss_plot.png\")"
   ],
   "id": "3e17ae7dda161a19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Plot Loss vs. Epoch",
   "id": "9bdc39571fe9c941"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Loss (D & G) per Epoch\")\n",
    "plt.plot(lossD_epoch, label=\"LossD (Epoch)\")\n",
    "plt.plot(lossG_epoch, label=\"LossG (Epoch)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"training_loss_epoch_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Plot saved: training_loss_epoch_plot.png\")"
   ],
   "id": "cd5d13c3663e1142"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
